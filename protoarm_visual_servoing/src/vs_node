#!/usr/bin/env python3

import sys

import cv2
import numpy as np
import rospy
import tf
from geometry_msgs.msg import Pose, PoseStamped
from sensor_msgs.msg import JointState

from tools.depth_image_processing import DepthImageProcessing

class VisualServoing:
    '''VisualServoing
    Implements position based visual servoing using depth image 
    '''

    def __init__(self):
        move_to_pose_topic = "/move_to_pose"
        move_to_joint_state_topic = "/move_to_joint_state"

        self.joint_names = ['Rev1', 'Rev2', 'Rev3', 'Rev4','Rev5']

        self.pose_pub = rospy.Publisher(
            move_to_pose_topic, PoseStamped, queue_size=1000)
        self.joint_state_pub = rospy.Publisher(
            move_to_joint_state_topic, JointState, queue_size=1000)
        self.tf_listener = tf.TransformListener()

    def wait_for_kinematics(self):
        r = rospy.Rate(10)
        while(self.pose_pub.get_num_connections() == 0):
            print("Waiting for move_to_pose to get setup")
            r.sleep()

        while(self.joint_state_pub.get_num_connections() == 0):
            print("Waiting for move_to_joint_state to get setup")
            r.sleep()

        rospy.sleep(2)

    def move_to_scan_pose(self):

        scan_pose = PoseStamped()
        scan_pose.pose.position.x = -0.20
        scan_pose.pose.position.y = 0
        scan_pose.pose.position.z = 0.238
        scan_pose.pose.orientation.x = 0 
        scan_pose.pose.orientation.y = 0
        scan_pose.pose.orientation.z = 0 
        scan_pose.pose.orientation.w = 1 
        scan_pose.header.stamp = rospy.Time.now() 
        scan_pose.header.frame_id = 'palm_1'

        self.pose_pub.publish(scan_pose)

    def focus_on_object(self, object_center, camera_center):
        if object_center and camera_center:
            object_center = np.array(object_center)
            camera_center = np.array(camera_center)
            diff = camera_center - camera_center

            try:
                (trans, rot) = self.tf_listener.lookupTransform(
                    '/camera_color_optical_frame', '/base_link', rospy.Time(0))
            except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException):
                pass

if __name__ == '__main__':
    rospy.init_node('vs_node')

    vs = VisualServoing()
    depth_proc = DepthImageProcessing()

    vs.wait_for_kinematics()

    vs.move_to_scan_pose()

    vs.focus_on_object(depth_proc.object_center, depth_proc.camera_center)

    '''
        r = Rate(10)
        while not rospy.is_shutdown():
                target_coord = depth_proc.get_target_coord()    
                if(target_coord is not None):
                        print(target_coord)
                        #vs.move_to_pose(target_coord)  
                        break
                r.sleep()
    '''

    rospy.spin()
